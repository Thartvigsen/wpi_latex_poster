\begin{thebibliography}{1}

\bibitem{campos2018skip}
V.~Campos, B.~Jou, X.~Giro-i Nieto, J.~Torres, and S.-F. Chang, ``Skip rnn:
  Learning to skip state updates in recurrent neural networks,'' in {\em
  International Conference on Learning Representations}, 2018.

\bibitem{che2018recurrent}
Z.~Che, S.~Purushotham, K.~Cho, D.~Sontag, and Y.~Liu, ``Recurrent neural
  networks for multivariate time series with missing values,'' {\em Scientific
  reports}, vol.~8, no.~1, p.~6085, 2018.

\bibitem{lipton2016modeling}
Z.~C. Lipton, D.~C. Kale, and R.~Wetzel, ``Modeling missing data in clinical
  time series with rnns,'' in {\em Machine Learning for Healthcare}, 2016.

\bibitem{neil2016phased}
D.~Neil, M.~Pfeiffer, and S.-C. Liu, ``Phased lstm: Accelerating recurrent
  network training for long or event-based sequences,'' in {\em Advances in
  Neural Information Processing Systems}, pp.~3882--3890, 2016.

\end{thebibliography}
